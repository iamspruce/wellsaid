from fastapi import APIRouter, Depends, Request
from pydantic import BaseModel
from app import models, prompts
from app.core.security import verify_api_key
import language_tool_python
import spacy
import difflib # Import the difflib module for text comparisons

router = APIRouter()

# Load the spaCy English language model for natural language processing tasks,
# such as dependency parsing for active/passive voice detection.
# IMPORTANT: If you get an OSError: [E050] Can't find model 'en_core_web_sm',
# you need to run: python -m spacy download en_core_web_sm in your terminal.
try:
    nlp = spacy.load("en_core_web_sm")
except OSError:
    print("SpaCy model 'en_core_web_sm' not found. Please run: python -m spacy download en_core_web_sm")
    # You might want to raise an HTTPException or provide a dummy NLP object
    # if the model is crucial for the application to function.
    # For now, we'll let it fail if not installed, as it's a critical dependency.
    raise

# Initialize LanguageTool for grammar, spelling, and style checking.
# 'en-US' specifies the English (United States) language.
tool = language_tool_python.LanguageTool('en-US')

class AnalyzeInput(BaseModel):
    """
    Pydantic BaseModel for validating the input request body for the /analyze endpoint.
    It expects a single field: 'text' (string).
    """
    text: str

# Apply the verify_api_key dependency at the router level for this endpoint.
# The Request object is now correctly handled without being wrapped by Depends.
@router.post("/analyze", dependencies=[Depends(verify_api_key)])
def analyze_text(payload: AnalyzeInput):
    """
    Analyzes the provided text for grammar, punctuation, sentence correctness,
    tone, active/passive voice, and inclusive pronoun suggestions.

    Args:
        payload (AnalyzeInput): The request body containing the text to be analyzed.
        (dependencies=[Depends(verify_api_key)]): Ensures the API key is verified before execution.

    Returns:
        dict: A dictionary containing various analysis results structured as per requirements.
    """
    text = payload.text

    # --- 1. Grammar Suggestions with Diffs ---
    # Get the grammatically corrected version of the original text.
    corrected_grammar = models.run_grammar_correction(text)
    
    grammar_changes = []
    # Use difflib to find differences between the original and corrected text.
    # We split by words to get word-level diffs, which are easier to interpret.
    s = difflib.SequenceMatcher(None, text.split(), corrected_grammar.split())
    
    # Iterate through the operations (opcodes) generated by SequenceMatcher.
    # 'equal', 'replace', 'delete', 'insert' are the types of operations.
    for opcode, i1, i2, j1, j2 in s.get_opcodes():
        if opcode == 'replace':
            # If words are replaced, format as "'original_word' -> 'corrected_word'"
            original_part = ' '.join(text.split()[i1:i2])
            corrected_part = ' '.join(corrected_grammar.split()[j1:j2])
            grammar_changes.append(f"'{original_part}' \u2192 '{corrected_part}'") # Using Unicode arrow
        elif opcode == 'delete':
            # If words are deleted, format as "'deleted_word' removed"
            deleted_part = ' '.join(text.split()[i1:i2])
            grammar_changes.append(f"'{deleted_part}' removed")
        elif opcode == 'insert':
            # If words are inserted, format as "'inserted_word' added"
            inserted_part = ' '.join(corrected_grammar.split()[j1:j2])
            grammar_changes.append(f"'{inserted_part}' added")

    # --- 2. Punctuation Fixes and 3. Sentence Correctness Feedback ---
    # LanguageTool checks the original text for various issues including punctuation.
    matches = tool.check(text)
    
    punctuation_issues = []
    sentence_correctness_feedback = []
    
    for m in matches:
        # Check if the rule ID (from LanguageTool) contains "PUNCTUATION" to categorize it.
        if 'PUNCTUATION' in m.ruleId.upper():
            punctuation_issues.append(m.message)
        else:
            # All other issues are considered general sentence correctness feedback.
            sentence_correctness_feedback.append(m.message)

    # --- 4. Tone Detection and Suggestion ---
    # Classify the tone of the original text using the fine-tuned emotion classifier.
    detected_tone = models.classify_tone(text)
    
    tone_suggestion_text = ""
    # Provide a simple tone suggestion based on the detected tone.
    # This logic can be expanded for more sophisticated suggestions based on context or user goals.
    if detected_tone in ["neutral", "joy"]: # Example: if text is neutral or joyful, suggest a formal alternative
        # Generate a formal tone version using FLAN-T5.
        tone_suggestion_text = models.run_flan_prompt(prompts.tone_prompt(text, "formal"))
    elif detected_tone == "anger":
        tone_suggestion_text = models.run_flan_prompt(prompts.tone_prompt(text, "calm and professional"))
    elif detected_tone == "sadness":
        tone_suggestion_text = models.run_flan_prompt(prompts.tone_prompt(text, "more uplifting"))
    else:
        # If no specific suggestion, indicate that the detected tone is generally fine.
        tone_suggestion_text = f"The detected tone '{detected_tone}' seems appropriate for general communication."


    # --- 5. Active/Passive Voice Detection and Suggestion ---
    doc = nlp(text) # Process the text with spaCy for linguistic analysis
    voice_detected = "active"
    voice_suggestion = "None \u2014 active voice is fine here." # Using Unicode em dash for better readability

    # Iterate through tokens to find passive auxiliary verbs (e.g., "is", "was", "been" when followed by a past participle).
    # A simple heuristic: if any token's dependency is 'auxpass', it's likely part of a passive construction.
    for token in doc:
        if token.dep_ == "auxpass":
            voice_detected = "passive"
            # If passive voice is detected, ask FLAN-T5 to rewrite it in active voice.
            better_voice_prompt = prompts.active_voice_prompt(text)
            voice_suggestion = models.run_flan_prompt(better_voice_prompt)
            break # Exit loop once passive voice is detected, no need to check further

    # --- 6. Inclusive Pronoun Suggestion ---
    # Use FLAN-T5 with a specific prompt to suggest more inclusive language.
    inclusive_pronouns_suggestion = models.run_flan_prompt(prompts.pronoun_friendly_prompt(text))

    # --- Construct the final response matching the example output structure ---
    return {
        "grammar": {
            "corrected": corrected_grammar,
            "changes": grammar_changes
        },
        "punctuation": {
            "issues": punctuation_issues,
            "suggestions": [] # The grammar correction and diffs implicitly handle suggestions here
        },
        "sentence_correctness": sentence_correctness_feedback,
        "tone_analysis": {
            "detected": detected_tone,
            "suggestion": tone_suggestion_text
        },
        "voice": {
            "detected": voice_detected,
            "suggestion": voice_suggestion
        },
        "inclusive_pronouns": inclusive_pronouns_suggestion
    }
